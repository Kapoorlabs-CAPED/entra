{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Covariance Optimization with Divergence-Free Transformation\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Sampling points from a uniform distribution\n",
    "2. Creating a divergence-free transformation with 5 centers\n",
    "3. Optimizing coefficients to minimize covariance determinant\n",
    "4. Visualizing before/after distributions\n",
    "5. Tracking entropy throughout optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from entra import (\n",
    "    VectorSampler, TensorBasis, Transformation, CovarianceMinimizer,\n",
    "    EffectiveTransformation, EffectiveCovarianceMinimizer,\n",
    "    shannon_entropy_gaussian, shannon_entropy_uniform, shannon_entropy_knn, plot_covariance_ellipse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 1: Sample Points from Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_points_per_dim = 20  # 10 points per dimension\n",
    "delta_x = 1          # Grid spacing in both x and y\n",
    "sigma = 5   # Sigma for tensor basis\n",
    "# Create sampler centered at origin\n",
    "sampler = VectorSampler(\n",
    "    center=[0.0, 0.0],\n",
    "    delta_x=delta_x,\n",
    "    num_points_per_dim=num_points_per_dim,\n",
    "    distribution=\"uniform\"\n",
    ")\n",
    "\n",
    "# Sample the grid points\n",
    "eval_points = sampler.sample()\n",
    "J = sampler.J\n",
    "grid_shape = sampler.num_points_per_dim\n",
    "\n",
    "print(f\"Grid: {num_points_per_dim} x {num_points_per_dim} = {J} points\")\n",
    "print(f\"Grid shape: {grid_shape}\")\n",
    "print(f\"delta_x = {delta_x}\")\n",
    "print(f\"sigma = {sigma}\")\n",
    "print(f\"\\neval_points shape: {eval_points.shape}  (J, D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the grid with point indices\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot all points\n",
    "ax.scatter(eval_points[:, 0], eval_points[:, 1], c='blue', s=100, zorder=2)\n",
    "\n",
    "\n",
    "\n",
    "# Mark the center (origin)\n",
    "ax.plot(0, 0, 'ro', markersize=15, zorder=3)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title(f'Sampled Grid Points: {num_points_per_dim}x{num_points_per_dim} = {J} points\\n'\n",
    "             f'delta_x = {delta_x}, centered at origin')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print grid extent\n",
    "print(f\"\\nGrid extent:\")\n",
    "print(f\"  x: [{eval_points[:, 0].min():.2f}, {eval_points[:, 0].max():.2f}]\")\n",
    "print(f\"  y: [{eval_points[:, 1].min():.2f}, {eval_points[:, 1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial statistics\n",
    "initial_mean = np.mean(eval_points, axis=0)\n",
    "initial_cov = np.cov(eval_points, rowvar=False)\n",
    "initial_det = np.linalg.det(initial_cov)\n",
    "initial_entropy_uniform = shannon_entropy_uniform(eval_points)\n",
    "initial_entropy_knn = shannon_entropy_knn(eval_points)\n",
    "\n",
    "print(\"Initial Distribution Statistics (Uniform):\")\n",
    "print(f\"  Mean: [{initial_mean[0]:.4f}, {initial_mean[1]:.4f}]\")\n",
    "print(f\"  Covariance:\")\n",
    "print(f\"    [[{initial_cov[0,0]:.6f}, {initial_cov[0,1]:.6f}],\")\n",
    "print(f\"     [{initial_cov[1,0]:.6f}, {initial_cov[1,1]:.6f}]]\")\n",
    "print(f\"  Determinant: {initial_det:.6e}\")\n",
    "print(f\"  Entropy (uniform): {initial_entropy_uniform:.6f} nats\")\n",
    "print(f\"  Entropy (k-NN):    {initial_entropy_knn:.6f} nats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86557220",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_list = []\n",
    "for i in range(int(eval_points[:, 0].max())):\n",
    "  center_list.append([i, 0.0])\n",
    "  center_list.append([-i, 0.0])\n",
    "  center_list.append([ 0.0, i])\n",
    "  center_list.append([0.0, -i])\n",
    "centers = np.asarray(center_list)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 2: Create 5 Centers and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basis and transformation\n",
    "basis = TensorBasis(centers, sigma=sigma)\n",
    "transformation = Transformation(basis)\n",
    "\n",
    "print(f\"TensorBasis: L={basis.L}, D={basis.D}, sigma={sigma}\")\n",
    "print(f\"Transformation: {transformation.num_parameters} parameters (L x D = {centers.shape} x {eval_points.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 3: Optimize Coefficients (Levenberg-Marquardt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create minimizer\n",
    "minimizer = CovarianceMinimizer(transformation, eval_points)\n",
    "\n",
    "# Track optimization history\n",
    "history = {\n",
    "    'iteration': [],\n",
    "    'determinant': [],\n",
    "    'entropy': [],\n",
    "    'log_det': []\n",
    "}\n",
    "\n",
    "# Custom optimization to record each step\n",
    "x = transformation.get_coefficients_flat().copy()\n",
    "n_params = len(x)\n",
    "\n",
    "lam = 1.0  # Damping\n",
    "eps = 1e-7\n",
    "max_iter = 1000\n",
    "tol = 1e-18\n",
    "\n",
    "# Record initial\n",
    "cov = minimizer.compute_covariance(x)\n",
    "det_val = np.linalg.det(cov)\n",
    "entropy = shannon_entropy_uniform(cov)\n",
    "history['iteration'].append(0)\n",
    "history['determinant'].append(det_val)\n",
    "history['entropy'].append(entropy)\n",
    "history['log_det'].append(np.log(det_val))\n",
    "\n",
    "print(f\"{'Iter':>5}  {'Determinant':>14}  {'Entropy':>12}  {'log(det)':>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{0:>5}  {det_val:>14.6e}  {entropy:>12.6f}  {np.log(det_val):>12.6f}\")\n",
    "\n",
    "for iteration in range(1, max_iter + 1):\n",
    "    r = minimizer.residuals_for_lm(x)\n",
    "    \n",
    "    # Jacobian\n",
    "    J_mat = np.zeros((len(r), n_params))\n",
    "    for i in range(n_params):\n",
    "        x_plus = x.copy()\n",
    "        x_plus[i] += eps\n",
    "        J_mat[:, i] = (minimizer.residuals_for_lm(x_plus) - r) / eps\n",
    "    \n",
    "    # LM step\n",
    "    JTJ = J_mat.T @ J_mat\n",
    "    JTr = J_mat.T @ r\n",
    "    \n",
    "    try:\n",
    "        delta = np.linalg.solve(JTJ + lam * np.eye(n_params), -JTr)\n",
    "    except:\n",
    "        delta = -JTr / (np.diag(JTJ) + lam + 1e-10)\n",
    "    \n",
    "    x_new = x + delta\n",
    "    obj_new = minimizer.objective_logdet(x_new)\n",
    "    obj_old = minimizer.objective_logdet(x)\n",
    "    #print(f'obj new {obj_new}, obj old {obj_old}')\n",
    "    if obj_new < obj_old:\n",
    "        x = x_new\n",
    "        lam *= 0.1\n",
    "        improvement = abs(obj_old - obj_new)\n",
    "        \n",
    "        cov = minimizer.compute_covariance(x)\n",
    "        det_val = np.linalg.det(cov)\n",
    "        entropy = shannon_entropy_gaussian(cov)\n",
    "        \n",
    "        history['iteration'].append(iteration)\n",
    "        history['determinant'].append(det_val)\n",
    "        history['entropy'].append(entropy)\n",
    "        history['log_det'].append(np.log(det_val))\n",
    "        \n",
    "        if iteration % 5 == 0 or iteration <= 5:\n",
    "            print(f\"{iteration:>5}  {det_val:>14.6e}  {entropy:>12.6f}  {np.log(det_val):>12.6f}\")\n",
    "        \n",
    "        if improvement < tol:\n",
    "            print(improvement, tol)\n",
    "            print(f\"\\nConverged at iteration {iteration}\")\n",
    "            break\n",
    "    else:\n",
    "        lam *= 10.0\n",
    "\n",
    "print(f\"\\nFinal: det = {det_val:.6e}, entropy = {entropy:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set final coefficients\n",
    "transformation.set_coefficients_flat(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Step 5: Optimization Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Determinant\n",
    "ax0 = axes[0]\n",
    "ax0.semilogy(history['iteration'], history['determinant'], 'b.-', linewidth=2, markersize=8)\n",
    "ax0.set_xlabel('Iteration', fontsize=12)\n",
    "ax0.set_ylabel('det(Cov)', fontsize=12)\n",
    "ax0.set_title('Determinant vs Iteration', fontsize=14)\n",
    "ax0.grid(True, alpha=0.3)\n",
    "\n",
    "# Log determinant\n",
    "ax1 = axes[1]\n",
    "ax1.plot(history['iteration'], history['log_det'], 'g.-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('log(det(Cov))', fontsize=12)\n",
    "ax1.set_title('Log-Determinant vs Iteration', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Entropy\n",
    "ax2 = axes[2]\n",
    "ax2.plot(history['iteration'], history['entropy'], 'r.-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Iteration', fontsize=12)\n",
    "ax2.set_ylabel('Entropy (nats)', fontsize=12)\n",
    "ax2.set_title('Shannon Entropy vs Iteration', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 6: Transform Points and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform points\n",
    "points_transformed = transformation.transform(eval_points)\n",
    "\n",
    "# Final statistics\n",
    "final_mean = np.mean(points_transformed, axis=0)\n",
    "final_cov = np.cov(points_transformed, rowvar=False)\n",
    "final_det = np.linalg.det(final_cov)\n",
    "final_entropy_gaussian = shannon_entropy_gaussian(final_cov)\n",
    "final_entropy_knn = shannon_entropy_knn(points_transformed)\n",
    "\n",
    "print(\"Comparison:\")\n",
    "print(f\"{'':20} {'Initial':>14} {'Final':>14} {'Change':>14}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Determinant':20} {initial_det:>14.6e} {final_det:>14.6e} {initial_det/final_det:>14.2f}x\")\n",
    "print(f\"{'Entropy (uniform)':20} {initial_entropy_uniform:>14.6f}\")\n",
    "print(f\"{'Entropy (gaussian)':20} {'':>14} {final_entropy_gaussian:>14.6f}\")\n",
    "print(f\"{'Entropy (k-NN)':20} {initial_entropy_knn:>14.6f} {final_entropy_knn:>14.6f} {initial_entropy_knn - final_entropy_knn:>14.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6mph0zih79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get updated basis after first iteration\n",
    "updated_basis = transformation.get_updated_basis(eval_points)  # (J, L, D)\n",
    "\n",
    "# Outer loop with updated basis\n",
    "N_OUTER = 5\n",
    "outer_history = {\n",
    "    'round': [0], \n",
    "    'determinant': [final_det], \n",
    "    'entropy': [final_entropy_gaussian],\n",
    "    'points': [points_transformed.copy()],\n",
    "    'covariance': [final_cov.copy()]\n",
    "}\n",
    "current_basis = updated_basis.copy()\n",
    "current_points = points_transformed.copy()\n",
    "\n",
    "print(f\"Starting outer loop with {N_OUTER} rounds\")\n",
    "print(f\"Initial basis shape: {current_basis.shape}\")\n",
    "print(f\"\\n{'Round':>5}  {'Determinant':>14}  {'Entropy':>12}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{0:>5}  {final_det:>14.6e}  {final_entropy_gaussian:>12.6f}\")\n",
    "\n",
    "for outer_round in range(1, N_OUTER + 1):\n",
    "    # Create effective transformation with current basis\n",
    "    eff_transform = EffectiveTransformation(current_basis, current_points)\n",
    "    eff_minimizer = EffectiveCovarianceMinimizer(eff_transform)\n",
    "    \n",
    "    # Optimize\n",
    "    result = eff_minimizer.optimize(max_iterations=500, tolerance=1e-10, verbose=False)\n",
    "    \n",
    "    # Record results\n",
    "    round_det = result['final_determinant']\n",
    "    round_cov = result['final_covariance']\n",
    "    round_entropy = shannon_entropy_gaussian(round_cov)\n",
    "    \n",
    "    # Update points for next round\n",
    "    current_points = eff_transform.transform()\n",
    "    current_basis = eff_transform.get_updated_basis()\n",
    "    \n",
    "    outer_history['round'].append(outer_round)\n",
    "    outer_history['determinant'].append(round_det)\n",
    "    outer_history['entropy'].append(round_entropy)\n",
    "    outer_history['points'].append(current_points.copy())\n",
    "    outer_history['covariance'].append(round_cov.copy())\n",
    "    \n",
    "    print(f\"{outer_round:>5}  {round_det:>14.6e}  {round_entropy:>12.6f}\")\n",
    "\n",
    "print(f\"\\nFinal reduction: {outer_history['determinant'][0] / outer_history['determinant'][-1]:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jw2h5b8rju",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outer loop progress\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.semilogy(outer_history['round'], outer_history['determinant'], 'bo-', linewidth=2, markersize=10)\n",
    "ax0.axhline(initial_det, color='r', linestyle='--', label=f'Initial: {initial_det:.2e}')\n",
    "ax0.set_xlabel('Outer Round', fontsize=12)\n",
    "ax0.set_ylabel('det(Cov)', fontsize=12)\n",
    "ax0.set_title('Determinant vs Outer Round', fontsize=14)\n",
    "ax0.legend()\n",
    "ax0.grid(True, alpha=0.3)\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.plot(outer_history['round'], outer_history['entropy'], 'go-', linewidth=2, markersize=10)\n",
    "ax1.axhline(initial_entropy_uniform, color='r', linestyle='--', label=f'Initial (uniform): {initial_entropy_uniform:.4f}')\n",
    "ax1.set_xlabel('Outer Round', fontsize=12)\n",
    "ax1.set_ylabel('Entropy (nats)', fontsize=12)\n",
    "ax1.set_title('Entropy vs Outer Round', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o2daxs837lp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution evolution through outer loop\n",
    "n_plots = 1 + len(outer_history['round'])  # Initial + all rounds (round 0 = after 1st iter)\n",
    "n_cols = min(4, n_plots)\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "axes = np.atleast_2d(axes).flatten()\n",
    "\n",
    "# Set consistent axis limits\n",
    "x_min = min(eval_points[:, 0].min(), min(p[:, 0].min() for p in outer_history['points']))\n",
    "x_max = max(eval_points[:, 0].max(), max(p[:, 0].max() for p in outer_history['points']))\n",
    "y_min = min(eval_points[:, 1].min(), min(p[:, 1].min() for p in outer_history['points']))\n",
    "y_max = max(eval_points[:, 1].max(), max(p[:, 1].max() for p in outer_history['points']))\n",
    "margin = 0.1 * max(x_max - x_min, y_max - y_min)\n",
    "\n",
    "# Plot 0: Initial uniform distribution\n",
    "ax = axes[0]\n",
    "ax.scatter(eval_points[:, 0], eval_points[:, 1], alpha=0.5, s=15, c='blue')\n",
    "plot_covariance_ellipse(ax, initial_mean, initial_cov, n_std=2, fill=False, color='green', linewidth=2)\n",
    "ax.set_xlim(x_min - margin, x_max + margin)\n",
    "ax.set_ylim(y_min - margin, y_max + margin)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title(f'Initial (Uniform)\\nH = {initial_entropy_uniform:.4f}')\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 1+: After each outer round (round 0 = after first iteration)\n",
    "for i, (rnd, pts, cov, det, ent) in enumerate(zip(\n",
    "    outer_history['round'], \n",
    "    outer_history['points'],\n",
    "    outer_history['covariance'],\n",
    "    outer_history['determinant'],\n",
    "    outer_history['entropy']\n",
    ")):\n",
    "    ax = axes[i + 1]\n",
    "    mean = np.mean(pts, axis=0)\n",
    "    \n",
    "    color = plt.cm.viridis(i / max(1, len(outer_history['round']) - 1))\n",
    "    ax.scatter(pts[:, 0], pts[:, 1], alpha=0.5, s=15, c=[color])\n",
    "    plot_covariance_ellipse(ax, mean, cov, n_std=2, fill=False, color='green', linewidth=2)\n",
    "    ax.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    if rnd == 0:\n",
    "        ax.set_title(f'After 1st Iteration\\ndet = {det:.2e}, H = {ent:.4f}')\n",
    "    else:\n",
    "        ax.set_title(f'Outer Round {rnd}\\ndet = {det:.2e}, H = {ent:.4f}')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused axes\n",
    "for j in range(n_plots, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distribution Evolution Through Optimization', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Before and After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Before transformation\n",
    "ax0 = axes[0]\n",
    "ax0.scatter(eval_points[:, 0], eval_points[:, 1], alpha=0.5, s=10, c='blue')\n",
    "ax0.scatter(centers[:, 0], centers[:, 1], c='red', s=100, marker='*', \n",
    "            zorder=5, edgecolors='black', label='Centers')\n",
    "plot_covariance_ellipse(ax0, initial_mean, initial_cov, n_std=2,\n",
    "                        fill=False, color='green', linewidth=2)\n",
    "ax0.set_xlim(2 * int(eval_points[:, 0].min()), 2 * int(eval_points[:, 0].max()))\n",
    "ax0.set_ylim(2 * int(eval_points[:, 1].min()), 2 * int(eval_points[:, 0].max()))\n",
    "ax0.set_xlabel('x', fontsize=12)\n",
    "ax0.set_ylabel('y', fontsize=12)\n",
    "ax0.set_title(f'BEFORE: Uniform Distribution\\n'\n",
    "              f'det = {initial_det:.4e}, H = {initial_entropy_uniform:.4f}', fontsize=14)\n",
    "ax0.set_aspect('equal')\n",
    "ax0.legend()\n",
    "ax0.grid(True, alpha=0.3)\n",
    "\n",
    "# After transformation\n",
    "ax1 = axes[1]\n",
    "ax1.scatter(points_transformed[:, 0], points_transformed[:, 1], alpha=0.5, s=10, c='orange')\n",
    "ax1.scatter(centers[:, 0], centers[:, 1], c='red', s=100, marker='*', \n",
    "            zorder=5, edgecolors='black', label='Centers')\n",
    "plot_covariance_ellipse(ax1, final_mean, final_cov, n_std=2,\n",
    "                        fill=False, color='green', linewidth=2)\n",
    "ax1.set_xlim(2 * int(eval_points[:, 0].min()), 2 * int(eval_points[:, 0].max()))\n",
    "ax1.set_ylim(2 * int(eval_points[:, 1].min()), 2 * int(eval_points[:, 0].max()))\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('y', fontsize=12)\n",
    "ax1.set_title(f'AFTER: Transformed Distribution\\n'\n",
    "              f'det = {final_det:.4e}, H = {final_entropy_gaussian:.4f}', fontsize=14)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Displacement Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid for displacement visualization\n",
    "n_grid = 20\n",
    "x_grid = np.linspace(-1.2, 1.2, n_grid)\n",
    "y_grid = np.linspace(-1.2, 1.2, n_grid)\n",
    "xx, yy = np.meshgrid(x_grid, y_grid, indexing='ij')\n",
    "grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Compute displacements\n",
    "displacements = transformation.get_displacement(grid_points)\n",
    "dx = displacements[:, 0].reshape(n_grid, n_grid)\n",
    "dy = displacements[:, 1].reshape(n_grid, n_grid)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot displacement field\n",
    "mag = np.sqrt(dx**2 + dy**2)\n",
    "ax.quiver(xx, yy, dx, dy, mag, cmap='coolwarm')\n",
    "\n",
    "# Plot centers\n",
    "ax.scatter(centers[:, 0], centers[:, 1], c='black', s=150, marker='*', \n",
    "           zorder=5, edgecolors='white', linewidths=2, label='Centers')\n",
    "\n",
    "ax.set_xlim(-3.3, 3.3)\n",
    "ax.set_ylim(-3.3, 3.3)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Displacement Field (Divergence-Free)', fontsize=14)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The optimization found transformation coefficients that:\n",
    "- Minimize the determinant of the covariance matrix\n",
    "- Reduce the Shannon entropy of the distribution\n",
    "- Use divergence-free displacement fields (preserving incompressibility)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
